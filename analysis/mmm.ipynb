{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import factorial\n",
    "\n",
    "import client as cp\n",
    "import middleware as mp\n",
    "\n",
    "# Matplot lib settings\n",
    "%matplotlib notebook\n",
    "matplotlib.rcParams.update({\n",
    "        'font.size': 11,\n",
    "        'font.family': 'sans-serif',\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10\n",
    "    })\n",
    "\n",
    "# Numpy settings\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(lam, mu, m):\n",
    "    rho = lam / (m * mu)\n",
    "    print('lambda', lam)\n",
    "    print('mu', mu)\n",
    "    print('m', m)\n",
    "    print('rho', rho)\n",
    "\n",
    "    p_0 = 1\n",
    "    p_0 += (np.power(m * rho, m) / (factorial(m, exact=True) * (1 - rho)))\n",
    "    for n in range(1, m):\n",
    "        p_0 += (np.power(m * rho, n) / factorial(n, exact=True))\n",
    "    p_0 = 1.0 / p_0\n",
    "#     print('p_0', p_0)\n",
    "    \n",
    "    p_q = np.power(m * rho, m) / (factorial(m, exact=True) * (1 - rho)) * p_0\n",
    "#     print('p_q', p_q)\n",
    "#     print()\n",
    "\n",
    "    E_r = 1 / mu * (1 + (p_q / (m * (1 - rho))))\n",
    "\n",
    "    E_w = p_q / (m * mu * (1 - rho))\n",
    "\n",
    "    E_n = m * rho + rho * p_q / (1 - rho)\n",
    "\n",
    "    E_nq = rho * p_q / (1 - rho)\n",
    "    \n",
    "    return [E_r * 1000, E_w * 1000, E_n, E_nq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [predict(lam, 21993 / 5, 5)[0] for lam in range(1, 21993, 2)]\n",
    "x = np.array(range(1, 21993, 2)) / 21993\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "plt.plot(x, a, label='M/M/m model')\n",
    "plt.xlabel('Traffic intensity')\n",
    "plt.ylabel('Response time (ms)')\n",
    "\n",
    "plt.scatter(bx, by, marker='o', label='Measured', color='red')\n",
    "plt.scatter(cx, cy, marker='d', label='Adjusted', color='green')\n",
    "\n",
    "plt.xlim([0, 1.1])\n",
    "plt.ylim([0, 50])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(0., 1., 1., 0.), loc=9, ncol=3, \n",
    "           mode=\"expand\", borderaxespad=0., fontsize='medium')\n",
    "plt.tight_layout()\n",
    "fig.savefig('mmm1.png', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "by = []\n",
    "bx = []\n",
    "\n",
    "cy = []\n",
    "cx = []\n",
    "\n",
    "base_dir = '/Users/ruifengxu/Development/asl-fall16-project/logs/maximum-throughput/thread-{}-client-{}/'\n",
    "\n",
    "thread_pool_size = 16\n",
    "\n",
    "for num_clients in [10, 40, 70, 100, 130]:\n",
    "    print('============================================')\n",
    "    print('thread pool size', thread_pool_size)\n",
    "    print('number clients', num_clients)\n",
    "    config = {\n",
    "        'request_type': 'g',\n",
    "        'start': 16,\n",
    "        'duration': 30,\n",
    "        'ci_coefficient': 2.776,\n",
    "        'num_repetitions': 5,\n",
    "        'num_client_vms': 3,\n",
    "        'num_clients_per_vm': num_clients,\n",
    "        'thread_pool_size': thread_pool_size,\n",
    "        'replication_factor': 1,\n",
    "        'base_dir': base_dir.format(thread_pool_size, num_clients)\n",
    "    } \n",
    "    client = cp.aggregate_data(config)\n",
    "    print('tp mean {:.3f}'.format(client['tp_mean']))\n",
    "    print('rt mean {:.3f}'.format(client['rt_mean']))\n",
    "    print()\n",
    "\n",
    "    lam = client['tp_mean']\n",
    "    m = 5\n",
    "    \n",
    "    config = {\n",
    "        'request_type': 'g',\n",
    "        'start': 16,\n",
    "        'duration': 45,\n",
    "        'num_repetitions': 5,\n",
    "        'base_dir': base_dir.format(thread_pool_size, num_clients)\n",
    "    }\n",
    "    middleware = mp.aggregate_data(config)\n",
    "    print('read request {:.3f}'.format(middleware['read_request']))\n",
    "    print('queue {:.3f}'.format(middleware['queue']))\n",
    "    print('forward request {:.3f}'.format(middleware['forward_request']))\n",
    "    print('server {:.3f}'.format(middleware['server']))\n",
    "    print('send response {:.3f}'.format(middleware['send_response']))\n",
    "    print('total {:.3f}'.format(middleware['total']))\n",
    "    print()\n",
    "        \n",
    "    total_clients = num_clients * 3\n",
    "    clients_in_network = (client['rt_mean'] - middleware['total']) * lam / 1000\n",
    "    clients_in_system = middleware['total'] * lam / 1000\n",
    "    clients_in_queue = middleware['queue'] * lam / 1000\n",
    "    clients_in_processing = clients_in_system - clients_in_queue\n",
    "    scaling_factor = clients_in_processing / m\n",
    "    print('total clients', total_clients)\n",
    "    print('clients in network', clients_in_network)\n",
    "    print('clients in system', clients_in_system)\n",
    "    print('clients in queue', clients_in_queue)\n",
    "    print('clients in processing', clients_in_processing)\n",
    "    print('scaling factor', scaling_factor)\n",
    "    print()\n",
    "        \n",
    "    measured = [\n",
    "        middleware['total'], \n",
    "        middleware['queue'], \n",
    "        lam * middleware['total'] / 1000, \n",
    "        lam * middleware['queue'] / 1000\n",
    "    ]        \n",
    "    print('{:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}'.format(*measured))\n",
    "    print()\n",
    "    \n",
    "    mu = 21993 / 5\n",
    "    prediction_maxtp = predict(lam, mu, m)\n",
    "    print('{:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}'.format(*prediction_maxtp))\n",
    "    print('{:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}'.format(*(np.array(prediction_maxtp) * scaling_factor)))\n",
    "    print()\n",
    "    \n",
    "    by.append(middleware['total'])\n",
    "    bx.append(lam / 21993)\n",
    "    cy.append((np.array(prediction_maxtp) * scaling_factor)[0])\n",
    "    cx.append(lam / 21993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "replication_factor = 1\n",
    "write_percentage = 10\n",
    "thread_pool_size = 16\n",
    "num_clients_per_vm = 110\n",
    "base_dir = '/Users/ruifengxu/Development/asl-fall16-project/logs/write/server-{}-replication-{}-write-{}/'\n",
    "\n",
    "for num_servers in [3, 5, 7]:\n",
    "    print('============================================')\n",
    "    print('number servers', num_servers)\n",
    "    config = {\n",
    "        'request_type': 'a',\n",
    "        'start': 16,\n",
    "        'duration': 30,\n",
    "        'ci_coefficient': 2.776,\n",
    "        'num_repetitions': 5,\n",
    "        'num_client_vms': 3,\n",
    "        'num_clients_per_vm': num_clients_per_vm,\n",
    "        'thread_pool_size': thread_pool_size,\n",
    "        'replication_factor': replication_factor,\n",
    "        'base_dir': base_dir.format(num_servers, replication_factor, write_percentage)\n",
    "    } \n",
    "    client = cp.aggregate_data(config)\n",
    "    print('tp mean {:.3f}'.format(client['tp_mean']))\n",
    "    print('rt mean {:.3f}'.format(client['rt_mean']))\n",
    "    print()\n",
    "\n",
    "    config = {\n",
    "        'request_type': 'g',\n",
    "        'start': 16,\n",
    "        'duration': 30,\n",
    "        'num_repetitions': 5,\n",
    "        'base_dir': base_dir.format(num_servers, replication_factor, write_percentage),\n",
    "    }\n",
    "    middleware_get = mp.aggregate_data(config)\n",
    "    print('read request {:.3f}'.format(middleware_get['read_request']))\n",
    "    print('queue {:.3f}'.format(middleware_get['queue']))\n",
    "    print('forward request {:.3f}'.format(middleware_get['forward_request']))\n",
    "    print('server {:.3f}'.format(middleware_get['server']))\n",
    "    print('send response {:.3f}'.format(middleware_get['send_response']))\n",
    "    print('total {:.3f}'.format(middleware_get['total']))\n",
    "    print()\n",
    "    \n",
    "    args = [16]\n",
    "    args.append((middleware_get['forward_request'] + middleware_get['server']) / 1000)\n",
    "\n",
    "    config['request_type'] = 's'\n",
    "    middleware_set = mp.aggregate_data(config)\n",
    "    print('read request {:.3f}'.format(middleware_set['read_request']))\n",
    "    print('queue {:.3f}'.format(middleware_set['queue']))\n",
    "    print('forward request {:.3f}'.format(middleware_set['forward_request']))\n",
    "    print('server {:.3f}'.format(middleware_set['server']))\n",
    "    print('send response {:.3f}'.format(middleware_set['send_response']))\n",
    "    print('total {:.3f}'.format(middleware_set['total']))\n",
    "    print()\n",
    "\n",
    "    args.append((middleware_set['forward_request'] + middleware_set['server']) / 1000)\n",
    "\n",
    "    w1 = 0.1\n",
    "    w2 = 0.9\n",
    "    middleware_read_request = w1 * middleware_set['read_request'] + w2 * middleware_get['read_request']\n",
    "    middleware_queue = w1 * middleware_set['queue'] + w2 * middleware_get['queue']\n",
    "    middleware_server = w1 * middleware_set['server'] + w2 * middleware_get['server']\n",
    "    middleware_total = w1 * middleware_set['total'] + w2 * middleware_get['total']\n",
    "    \n",
    "    args.append((client['rt_mean'] - middleware_total) / 1000)\n",
    "    args.append(middleware_read_request / 1000)\n",
    "\n",
    "\n",
    "    lam = client['tp_mean']\n",
    "    m = num_servers\n",
    "    \n",
    "#     print('{}, {:.10f}, {:.10f}, {:.10f}, {:.10f}'.format(*args))\n",
    "    measured = [\n",
    "        middleware_total,\n",
    "        middleware_queue,\n",
    "        lam * middleware_total / 1000, \n",
    "        lam * middleware_queue / 1000\n",
    "    ]        \n",
    "    print('{:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}'.format(*measured))\n",
    "    \n",
    "    mu = 1 / middleware_server * 1000 * 17\n",
    "    prediction_maxtp = predict(lam, mu, m)\n",
    "    print('{:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}'.format(*prediction_maxtp))\n",
    "    print('{:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}'.format(*(np.array(prediction_maxtp) * 17)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
