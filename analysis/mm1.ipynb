{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import client as cp\n",
    "import middleware as mp\n",
    "\n",
    "# Matplot lib settings\n",
    "%matplotlib notebook\n",
    "matplotlib.rcParams.update({\n",
    "        'font.size': 11,\n",
    "        'font.family': 'sans-serif',\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10\n",
    "    })\n",
    "\n",
    "# Numpy settings\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/ruifengxu/Development/asl-fall16-project/logs/trace/'\n",
    "client_log_template = 'client-{}.log'\n",
    "middleware_log_template = 'trace.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_client_data(thread_pool_size, num_clients, num_client_machines, start, duration):\n",
    "    end = start + duration\n",
    "                \n",
    "    client_tp = 0\n",
    "            \n",
    "    client_rts = np.zeros(num_client_machines * duration)\n",
    "    client_rts_weight = np.zeros(num_client_machines * duration)\n",
    "    client_rts_index = 0\n",
    "    client_rts_bucket = None\n",
    "\n",
    "    for log_id in range(1, num_client_machines + 1, 1):\n",
    "        filename = os.path.join(\n",
    "            base_dir,\n",
    "            client_log_template.format(log_id)\n",
    "        )\n",
    "        data = cp.parse_log(filename)\n",
    "\n",
    "        num_ops = data['all_global'][end - 2]['num_ops'] - data['all_global'][start - 2]['num_ops']\n",
    "        \n",
    "        client_tp += (num_ops // duration)\n",
    "                    \n",
    "        for entry in data['all_local'][start - 1: end - 1]:\n",
    "            client_rts[client_rts_index] = entry['rt_mean']\n",
    "            client_rts_weight[client_rts_index] = entry['num_ops']\n",
    "            client_rts_index = client_rts_index + 1\n",
    "\n",
    "        if client_rts_bucket is None:\n",
    "            client_rts_bucket = list(data['all_bucket'])\n",
    "        else:\n",
    "            client_rts_bucket = [x + y for x, y in zip(client_rts_bucket, data['all_bucket'])]\n",
    "        \n",
    "    client_rt_mean = np.average(client_rts, weights=client_rts_weight)\n",
    "    client_rt_low = cp.get_percentile(client_rts_bucket, 5)\n",
    "    client_rt_high = cp.get_percentile(client_rts_bucket, 95)\n",
    "            \n",
    "    print('{:6.0f} {:6.3f} {:6.3f} {:6.3f} {:6.3f}'.format(\n",
    "            client_tp,\n",
    "            client_rt_mean, client_rt_low, client_rt_high,\n",
    "            1 / client_rt_mean * 1000 * num_clients * num_client_machines / client_tp))    \n",
    "    \n",
    "    return {\n",
    "        'tp_mean': client_tp,\n",
    "        'tp_std': 0,\n",
    "        'tp_ci': 0,\n",
    "        'rt_mean': client_rt_mean,\n",
    "        'rt_low': client_rt_low,\n",
    "        'rt_high': client_rt_high\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = process_client_data(16, 64, 3, 601, 4200)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_middleware_data(start, duration):\n",
    "    read_request_times = []\n",
    "    queue_times = []\n",
    "    send_request_times = []\n",
    "    read_response_times = []\n",
    "    send_response_times = []\n",
    "    total_times = []\n",
    "        \n",
    "    filename = os.path.join(base_dir, middleware_log_template)\n",
    "    data = mp.parse_log(filename, request_type='g')\n",
    "    start_time = data[0][2] + start\n",
    "    end_time = start_time + duration\n",
    "    \n",
    "    for entry in data:                                                \n",
    "        if entry[2] < start_time:\n",
    "            continue\n",
    "        if entry[2] == end_time:\n",
    "            break\n",
    "        if entry[6] is False:\n",
    "            continue\n",
    "        read_request_times.append(entry[8])\n",
    "        queue_times.append(entry[9])\n",
    "        send_request_times.append(entry[10])\n",
    "        read_response_times.append(entry[11])\n",
    "        send_response_times.append(entry[12])\n",
    "        total_times.append(np.sum(entry[8:13])) \n",
    "    \n",
    "    return {\n",
    "        'read_request': np.mean(read_request_times) / 1000000, \n",
    "        'queue': np.mean(queue_times) / 1000000, \n",
    "        'forward_request': np.mean(send_request_times) / 1000000, \n",
    "        'server': np.mean(read_response_times) / 1000000, \n",
    "        'send_response': np.mean(send_response_times) / 1000000, \n",
    "        'total': np.mean(total_times) / 1000000\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "middleware = process_middleware_data(601, 4200)\n",
    "print(middleware['read_request'])\n",
    "print(middleware['queue'])\n",
    "print(middleware['forward_request'])\n",
    "print(middleware['server'])\n",
    "print(middleware['send_response'])\n",
    "print(middleware['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_middleware_operation_percentiles(percentile_config, start, duration):\n",
    "    read_request_times = []\n",
    "    queue_times = []\n",
    "    send_request_times = []\n",
    "    read_response_times = []\n",
    "    send_response_times = []\n",
    "    total_times = []\n",
    "\n",
    "    filename = os.path.join(base_dir, middleware_log_template)\n",
    "\n",
    "    data = mp.parse_log(filename, request_type='g')\n",
    "    start_time = data[0][2] + start\n",
    "    end_time = start_time + duration\n",
    "    for entry in data:                                                \n",
    "        if entry[2] < start_time:\n",
    "            continue\n",
    "        if entry[2] == end_time:\n",
    "            break\n",
    "        if entry[6] is False:\n",
    "            continue\n",
    "\n",
    "        read_request_times.append(entry[8])\n",
    "        queue_times.append(entry[9])\n",
    "        send_request_times.append(entry[10])\n",
    "        read_response_times.append(entry[11])\n",
    "        send_response_times.append(entry[12])\n",
    "        total_times.append(np.sum(entry[8: 13])) \n",
    "\n",
    "    return {\n",
    "        'read_request': np.percentile(read_request_times, percentile_config) / 1000000,\n",
    "        'queue': np.percentile(queue_times, percentile_config) / 1000000,\n",
    "        'forward_request': np.percentile(send_request_times, percentile_config) / 1000000,\n",
    "        'server': np.percentile(read_response_times, percentile_config) / 1000000,\n",
    "        'send_response': np.percentile(send_response_times, percentile_config) / 1000000,\n",
    "        'total': np.percentile(total_times, percentile_config) / 1000000\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentiles = get_middleware_operation_percentiles([50, 99], 601, 4200)\n",
    "print(percentiles['read_request'])\n",
    "print(percentiles['queue'])\n",
    "print(percentiles['forward_request'])\n",
    "print(percentiles['server'])\n",
    "print(percentiles['send_response'])\n",
    "print(percentiles['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = client['tp_mean']\n",
    "\n",
    "processing_time = (middleware['forward_request'] + middleware['server'] + middleware['send_response']) / 1000\n",
    "\n",
    "m = 1 / processing_time * 17 * 3\n",
    "\n",
    "r = l / m\n",
    "\n",
    "print('lambda', l)\n",
    "print('mu', m)\n",
    "print('rho', l / m)\n",
    "print()\n",
    "\n",
    "print('Measured')\n",
    "print('E[r]', middleware['total'])\n",
    "print('E[w]', middleware['queue'])\n",
    "print('E[n]', l * middleware['total'] / 1000)\n",
    "print('E[nq]', l * middleware['queue'] / 1000)\n",
    "print()\n",
    "\n",
    "print('Prediction')\n",
    "print('E[r]', 1 / m / (1-r) * 1000)\n",
    "print('E[w]', r / m / (1-r) * 1000)\n",
    "print('E[n]', r / (1 - r))\n",
    "print('E[nq]', r * r / (1 - r))\n",
    "print()\n",
    "\n",
    "print('Adjusted Prediction')\n",
    "print('E[r]', 1 / m / (1-r) * 1000 * 51)\n",
    "print('E[w]', r / m / (1-r) * 1000 * 51)\n",
    "print('E[n]', 1 / m / (1-r) * 51 * l)\n",
    "print('E[nq]', r / m / (1-r) * 51 * l)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
